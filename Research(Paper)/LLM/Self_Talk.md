# Bootstrapping LLM-based Task-Oriented Dialogue Agents via Self-Talk

[html site information](https://browse.arxiv.org/html/2401.05033v1)

## Abstract

Large language models (LLMs) are powerful dialogue agents, but specializing them towards fulfilling a specific function can be challenging.  Instructing tuning, i.e. tuning models on instruction and sample responses generated by humans (Ouyang et al., 2022), has proven as an effective method to do so, yet requires a number of data samples that a) might not be available or b) costly to generate. Furthermore, this cost increases when the goal is to make the LLM follow a specific workflow within a dialogue instead of single instructions. Inspired by the self-play technique in reinforcement learning and the use of LLMs to simulate human agents, we propose a more effective method for data collection through LLMs engaging in a conversation in various roles. This approach generates a training data via "self-talk" of LLMs that can be refined and utilized for supervised fine-tuning. We introduce an automated way to measure the (partial) success of a dialogue. This metric is used to filter the generated conversational data that is fed back in LLM for training. Based on our automated and human evaluations of conversation quality, we demonstrate that such self-talk data improves results. In addition, we examine the various characteristics that showcase the quality of generated dialogues and how they can be connected to their potential utility as training data.

LLM(대형 언어 모델)은 강력한 대화 에이전트이지만 특정 기능을 수행하기 위해 이를 전문화하는 것은 어려울 수 있습니다. 지시 튜닝, 즉 인간이 생성한 지시 및 샘플 응답에 대한 모델 튜닝(Ouyang et al., 2022)은 이를 위한 효과적인 방법으로 입증되었지만 a) 사용 가능하지 않을 수 있는 많은 데이터 샘플이 필요하거나 b) 생성하는 데 비용이 많이 듭니다. 또한 LLM이 단일 지침이 아닌 대화 내에서 특정 작업 흐름을 따르도록 하는 것이 목표인 경우 이 비용이 증가합니다. 강화 학습의 셀프 플레이 기술과 LLM을 사용하여 인간 에이전트를 시뮬레이션하는 방법에서 영감을 받아 다양한 역할로 대화에 참여하는 LLM을 통해 데이터 수집을 위한 보다 효과적인 방법을 제안합니다. 이 접근 방식은 LLM의 "자기 대화"를 통해 감독된 미세 조정을 위해 정제되고 활용될 수 있는 훈련 데이터를 생성합니다. 우리는 대화의 (부분적인) 성공을 측정하는 자동화된 방법을 소개합니다. 이 지표는 훈련을 위해 LLM에서 피드백되는 생성된 대화 데이터를 필터링하는 데 사용됩니다. 대화 품질에 대한 자동화된 인간 평가를 기반으로 이러한 자기 대화 데이터가 결과를 향상시킨다는 것을 보여줍니다. 또한 생성된 대화의 품질을 보여주는 다양한 특성과 이것이 훈련 데이터로서의 잠재적 유용성과 어떻게 연결될 수 있는지 조사합니다.